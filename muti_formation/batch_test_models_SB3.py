"""
æ‰¹é‡æµ‹è¯•å¤šä¸ªSB3 PPO checkpointæ¨¡å‹
ç”¨äºæ‰¾å‡ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„æœ€ä½³æ¨¡å‹
"""
import subprocess
import sys
from pathlib import Path
import json
import pandas as pd
import numpy as np

def test_checkpoint(model_path, episodes=50):
    """æµ‹è¯•å•ä¸ªSB3 checkpoint"""
    print(f"\n{'='*80}")
    print(f"æµ‹è¯•æ¨¡å‹: {model_path}")
    print(f"{'='*80}")
    
    cmd = [
        sys.executable,
        "muti_formation/test_phase1_SB3.py",
        "--model", str(model_path),
        "--episodes", str(episodes),
        "--no_render",  # æ‰¹é‡æµ‹è¯•æ—¶ä¸æ¸²æŸ“
        "--save_dir", "muti_formation/agent/log_SB3/test_results"
    ]
    
    try:
        subprocess.run(cmd, check=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def collect_results():
    """æ”¶é›†æ‰€æœ‰SB3æµ‹è¯•ç»“æœ"""
    log_dir = Path("muti_formation/agent/log_SB3")
    results = []
    
    if not log_dir.exists():
        print(f"âš ï¸ æµ‹è¯•ç»“æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {log_dir}")
        return results
    
    for result_file in log_dir.glob("phase1_test_results_*.json"):
        try:
            with open(result_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            model_name = result_file.stem.replace("phase1_test_results_", "")
            
            # æå–å…³é”®æŒ‡æ ‡
            num_episodes = len(data['episode_rewards'])
            if num_episodes == 0:
                continue
            
            success_rate = data['success_count'] / num_episodes
            collision_rate = data['collision_count'] / num_episodes
            timeout_rate = data['timeout_count'] / num_episodes
            boundary_collision_rate = data['boundary_collision_count'] / num_episodes
            physical_collision_rate = data['physical_collision_count'] / num_episodes
            
            avg_reward = np.mean(data['episode_rewards'])
            std_reward = np.std(data['episode_rewards'])
            avg_length = np.mean(data['episode_lengths'])
            
            # å¹³å‡æœ€å°æ·±åº¦å’Œç›®æ ‡è·ç¦»
            avg_min_depth = np.mean(data['min_depths']) if data.get('min_depths') else 0
            avg_goal_distance = np.mean(data['goal_distances']) if data.get('goal_distances') else 0
            
            # å¥–åŠ±åˆ†é‡åˆ†æ
            reward_components = data.get('reward_components', {})
            avg_success_reward = np.mean(reward_components.get('success', [0]))
            avg_crash_reward = np.mean(reward_components.get('crash', [0]))
            avg_dense_reward = np.mean(reward_components.get('dense', [0]))
            
            # è®¡ç®—æˆåŠŸæ—¶çš„å¹³å‡å¥–åŠ±å’Œç¢°æ’æ—¶çš„å¹³å‡å¥–åŠ±
            success_episode_rewards = [r for i, r in enumerate(data['episode_rewards']) 
                                      if i < len(data['episode_rewards']) and data['success_count'] > 0]
            collision_episode_rewards = [r for i, r in enumerate(data['episode_rewards']) 
                                        if i < len(data['episode_rewards']) and data['collision_count'] > 0]
            
            avg_success_episode_reward = np.mean(success_episode_rewards) if success_episode_rewards else 0
            avg_collision_episode_reward = np.mean(collision_episode_rewards) if collision_episode_rewards else 0
            
            # æˆåŠŸ/ç¢°æ’æ¯”
            success_fail_ratio = avg_success_episode_reward / avg_collision_episode_reward if avg_collision_episode_reward != 0 else 0
            
            results.append({
                'model': model_name,
                'episodes': num_episodes,
                'success_rate': success_rate,
                'collision_rate': collision_rate,
                'timeout_rate': timeout_rate,
                'boundary_collision_rate': boundary_collision_rate,
                'physical_collision_rate': physical_collision_rate,
                'avg_reward': avg_reward,
                'std_reward': std_reward,
                'avg_length': avg_length,
                'avg_min_depth': avg_min_depth,
                'avg_goal_distance': avg_goal_distance,
                'avg_success_reward': avg_success_reward,
                'avg_crash_reward': avg_crash_reward,
                'avg_dense_reward': avg_dense_reward,
                'avg_success_episode_reward': avg_success_episode_reward,
                'avg_collision_episode_reward': avg_collision_episode_reward,
                'success_fail_ratio': success_fail_ratio
            })
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ–‡ä»¶ {result_file} æ—¶å‡ºé”™: {e}")
            continue
    
    return results

def generate_comparison_report(results):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    if not results:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•ç»“æœ")
        return
    
    df = pd.DataFrame(results)
    df = df.sort_values('success_rate', ascending=False)
    
    print("\n" + "="*140)
    print("ğŸ“Š SB3 PPOæ¨¡å‹å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    print("="*140)
    
    print("\nğŸ† æŒ‰æˆåŠŸç‡æ’åº:")
    print("-"*140)
    print(f"{'æ¨¡å‹åç§°':<45} | {'å›åˆ':>5} | {'æˆåŠŸç‡':>8} | {'ç¢°æ’ç‡':>8} | {'è¶…æ—¶ç‡':>8} | {'å¹³å‡å¥–åŠ±':>10} | {'å¥–åŠ±æ ‡å‡†å·®':>10} | {'å¹³å‡æ­¥æ•°':>8}")
    print("-"*140)
    
    for _, row in df.iterrows():
        print(f"{row['model']:<45} | "
              f"{row['episodes']:>5d} | "
              f"{row['success_rate']:>7.1%} | "
              f"{row['collision_rate']:>7.1%} | "
              f"{row['timeout_rate']:>7.1%} | "
              f"{row['avg_reward']:>10.2f} | "
              f"{row['std_reward']:>10.2f} | "
              f"{row['avg_length']:>8.1f}")
    
    print("-"*140)
    
    # è¯¦ç»†åˆ†æè¡¨
    print("\nğŸ“ˆ è¯¦ç»†åˆ†æ:")
    print("-"*140)
    print(f"{'æ¨¡å‹åç§°':<45} | {'è¾¹ç•Œç¢°æ’':>9} | {'ç‰©ç†ç¢°æ’':>9} | {'æœ€å°æ·±åº¦':>9} | {'ç›®æ ‡è·ç¦»':>9} | {'æˆåŠŸ/ç¢°æ’æ¯”':>12}")
    print("-"*140)
    
    for _, row in df.iterrows():
        print(f"{row['model']:<45} | "
              f"{row['boundary_collision_rate']:>8.1%} | "
              f"{row['physical_collision_rate']:>8.1%} | "
              f"{row['avg_min_depth']:>8.2f}m | "
              f"{row['avg_goal_distance']:>8.2f}m | "
              f"{row['success_fail_ratio']:>11.2f}:1")
    
    print("-"*140)
    
    # å¥–åŠ±åˆ†é‡åˆ†æ
    print("\nğŸ’° å¥–åŠ±åˆ†é‡åˆ†æ:")
    print("-"*140)
    print(f"{'æ¨¡å‹åç§°':<45} | {'æˆåŠŸå¥–åŠ±':>10} | {'ç¢°æ’æƒ©ç½š':>10} | {'å¯†é›†å¥–åŠ±':>10} | {'æˆåŠŸå›åˆå¥–åŠ±':>12} | {'ç¢°æ’å›åˆå¥–åŠ±':>12}")
    print("-"*140)
    
    for _, row in df.iterrows():
        print(f"{row['model']:<45} | "
              f"{row['avg_success_reward']:>10.2f} | "
              f"{row['avg_crash_reward']:>10.2f} | "
              f"{row['avg_dense_reward']:>10.2f} | "
              f"{row['avg_success_episode_reward']:>12.2f} | "
              f"{row['avg_collision_episode_reward']:>12.2f}")
    
    print("-"*140)
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_model = df.iloc[0]
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼ˆæŒ‰æˆåŠŸç‡ï¼‰: {best_model['model']}")
    print(f"   æµ‹è¯•å›åˆ: {best_model['episodes']}")
    print(f"   æˆåŠŸç‡: {best_model['success_rate']:.1%}")
    print(f"   ç¢°æ’ç‡: {best_model['collision_rate']:.1%}")
    print(f"   è¶…æ—¶ç‡: {best_model['timeout_rate']:.1%}")
    print(f"   å¹³å‡å¥–åŠ±: {best_model['avg_reward']:.2f} Â± {best_model['std_reward']:.2f}")
    print(f"   å¹³å‡æ­¥æ•°: {best_model['avg_length']:.1f}")
    print(f"   å¹³å‡æœ€å°æ·±åº¦: {best_model['avg_min_depth']:.2f}m")
    print(f"   å¹³å‡ç›®æ ‡è·ç¦»: {best_model['avg_goal_distance']:.2f}m")
    print(f"   æˆåŠŸ/ç¢°æ’æ¯”: {best_model['success_fail_ratio']:.2f}:1")
    
    # æ‰¾å‡ºå¹³å‡å¥–åŠ±æœ€é«˜çš„æ¨¡å‹
    best_reward_model = df.loc[df['avg_reward'].idxmax()]
    if best_reward_model['model'] != best_model['model']:
        print(f"\nğŸ’ æœ€é«˜å¹³å‡å¥–åŠ±æ¨¡å‹: {best_reward_model['model']}")
        print(f"   å¹³å‡å¥–åŠ±: {best_reward_model['avg_reward']:.2f}")
        print(f"   æˆåŠŸç‡: {best_reward_model['success_rate']:.1%}")
    
    # æ‰¾å‡ºæœ€ç¨³å®šçš„æ¨¡å‹ï¼ˆæ ‡å‡†å·®æœ€å°ï¼‰
    best_stable_model = df.loc[df['std_reward'].idxmin()]
    if best_stable_model['model'] not in [best_model['model'], best_reward_model['model']]:
        print(f"\nâš–ï¸  æœ€ç¨³å®šæ¨¡å‹ï¼ˆæ ‡å‡†å·®æœ€å°ï¼‰: {best_stable_model['model']}")
        print(f"   å¥–åŠ±æ ‡å‡†å·®: {best_stable_model['std_reward']:.2f}")
        print(f"   æˆåŠŸç‡: {best_stable_model['success_rate']:.1%}")
    
    # ä¿å­˜æŠ¥å‘Š
    log_dir = Path("muti_formation/agent/log_SB3")
    report_path = log_dir / "model_comparison_report.csv"
    df.to_csv(report_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ“„ è¯¦ç»†å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # ä¿å­˜ç®€åŒ–ç‰ˆæŠ¥å‘Šï¼ˆåªåŒ…å«å…³é”®æŒ‡æ ‡ï¼‰
    simplified_df = df[['model', 'episodes', 'success_rate', 'collision_rate', 'avg_reward', 
                        'avg_length', 'avg_min_depth', 'success_fail_ratio']]
    simplified_report_path = log_dir / "model_comparison_summary.csv"
    simplified_df.to_csv(simplified_report_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ“„ ç®€åŒ–æŠ¥å‘Šå·²ä¿å­˜: {simplified_report_path}")
    
    print("="*140)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯•SB3 PPOæ¨¡å‹")
    
    # å®šä¹‰è¦æµ‹è¯•çš„checkpoint
    model_dir = Path("muti_formation/agent/model_SB3")
    
    if not model_dir.exists():
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
        return
    
    # æ–¹å¼1: æµ‹è¯•æ‰€æœ‰checkpoint
    # checkpoints = sorted(model_dir.glob("leader_phase1_episode_*.zip"))
    
    # æ–¹å¼2: æµ‹è¯•ç‰¹å®šcheckpointï¼ˆæ¨èï¼‰
    episodes_to_test = [30000, 35000, 40000, 45000, 50000, 55000, 'final']  # ğŸ”§ æ ¹æ®éœ€è¦è°ƒæ•´
    checkpoints = []
    for ep in episodes_to_test:
        if ep == 'final':
            checkpoint_path = model_dir / "leader_phase1_final"
        else:
            checkpoint_path = model_dir / f"leader_phase1_episode_{ep}"
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼ˆä¸å«.zipåç¼€ï¼ŒSB3ä¼šè‡ªåŠ¨æ·»åŠ ï¼‰
        if (checkpoint_path.parent / (checkpoint_path.name + '.zip')).exists():
            checkpoints.append(checkpoint_path)
        else:
            print(f"âš ï¸ æ¨¡å‹ä¸å­˜åœ¨: {checkpoint_path}.zip")
    
    if not checkpoints:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
        print(f"è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶ä½äº: {model_dir}")
        print("æ¨¡å‹æ–‡ä»¶å‘½åæ ¼å¼: leader_phase1_episode_*.zip æˆ– leader_phase1_final.zip")
        return
    
    print(f"æ‰¾åˆ° {len(checkpoints)} ä¸ªæ¨¡å‹å¾…æµ‹è¯•")
    print(f"æ¨¡å‹åˆ—è¡¨: {[c.name for c in checkpoints]}")
    
    # æµ‹è¯•æ¯ä¸ªcheckpoint
    for i, checkpoint in enumerate(checkpoints, 1):
        print(f"\nè¿›åº¦: [{i}/{len(checkpoints)}]")
        test_checkpoint(checkpoint, episodes=200)  # ğŸ”§ å¯è°ƒæ•´æµ‹è¯•å›åˆæ•°
    
    # æ”¶é›†å¹¶åˆ†æç»“æœ
    print("\n" + "="*80)
    print("ğŸ“Š æ”¶é›†æµ‹è¯•ç»“æœ...")
    print("="*80)
    results = collect_results()
    
    if results:
        generate_comparison_report(results)
    else:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•ç»“æœ")
        print("è¯·æ£€æŸ¥æµ‹è¯•æ˜¯å¦æˆåŠŸå®Œæˆï¼Œä»¥åŠç»“æœæ–‡ä»¶æ˜¯å¦ä¿å­˜åœ¨ log_SB3/ ç›®å½•")

if __name__ == '__main__':
    main()
