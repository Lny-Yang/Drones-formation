from __future__ import annotations
import math, random
from typing import List, Tuple, Dict, Any
import gym, numpy as np, pybullet as p
import pybullet_data
from ..resources.drone import Drone
from ..utils.depth_obstacle_processor import DepthObstacleProcessor
from ..utils.reward_calculator import RewardCalculator, create_default_reward_config
from ..utils.state_processor import StateProcessor, create_default_state_config
from ..utils.environment_manager import EnvironmentManager, create_default_environment_config
from ..utils.camera_manager import CameraManager, create_default_camera_config
from ..utils.observation_manager import ObservationSpaceManager, create_default_observation_config
from ..config import multi_drone_env as config
import time
__all__ = ["DroneNavigationMulti"]

class DroneNavigationMulti(gym.Env):
    
    """ç®€åŒ–ç‰ˆå¤šæ— äººæœºå•ç›®æ ‡ç¼–é˜Ÿå¯¼èˆªç¯å¢ƒ - ä¸“ä¸ºåˆ†é˜¶æ®µCTDEè®­ç»ƒè®¾è®¡"""

    metadata = {"render_modes": ["human"], "render_fps": 15}

    def __init__(self,
                 num_drones: int = 5,
                 environment_type: str = "indoor",  # æ¢å¤ï¼šé»˜è®¤ä½¿ç”¨å®¤å†…ç¯å¢ƒï¼Œä¸ç”¨æˆ·åŸå§‹ç¯å¢ƒä¸€è‡´
                 enforce_planar: bool | None = None,
                 use_depth_camera: bool = True,
                 depth_camera_range: float = 10.0,
                 camera_pixel: int = 64,
                 depth_resolution: int = 16,
                 formation_distance: float = config.get("formation_distance", 0.05),
                 max_steps: int = 3000,  # ä¿®å¤ï¼šä»1500å¢åŠ åˆ°3000ï¼Œç»™äºˆå……è¶³æ—¶é—´åˆ°è¾¾ç›®æ ‡
                 success_radius_xy: float = 2.5,  # ä¿®å¤ï¼šä»1.5å¢åŠ åˆ°2.5ç±³ï¼Œæ”¾å®½æˆåŠŸæ¡ä»¶
                 success_height_tol: float = 0.5,  # ä¿®å¤ï¼šä»1.0é™ä½åˆ°0.5ç±³ï¼Œæé«˜ç²¾åº¦è¦æ±‚
                 catchup_gain_pos: float = 1.5,
                 catchup_gain_pos_z: float = 2.0,
                 catchup_gain_speed: float = 2.0,
                 catchup_speed_target: float = 5.0,
                 catchup_max_force_xy: float = 8.0,
                 catchup_max_force_z: float = 6.0,
                 dt: float = 1/30,
                 use_leader_camera: bool = True,
                 enable_formation_force: bool = False,
                 training_stage: int = 1,
                 # æ–°å¢ï¼šç›¸æœºé…ç½®å‚æ•°
                 enable_fixed_overhead_camera: bool = False,  # æ˜¯å¦å¯ç”¨å›ºå®šä¿¯è§†æ‘„åƒå¤´
                 fixed_camera_height: float = 3.0,  # å›ºå®šæ‘„åƒå¤´é«˜åº¦
                 fixed_camera_pitch: float = 1.5):  # å›ºå®šæ‘„åƒå¤´ä¿¯ä»°è§’
        # åŸºæœ¬å‚æ•°
        self.num_drones = num_drones
        self.environment_type = environment_type
        self.enforce_planar = config.get("enforce_planar", True)  # ä»é…ç½®æ–‡ä»¶è¯»å–å¹³é¢æ¨¡å¼è®¾ç½®
        self.use_leader_camera = use_leader_camera and use_depth_camera
        self.use_depth_camera = use_depth_camera
        self.depth_camera_range = depth_camera_range
        self.camera_pixel = camera_pixel
        self.depth_resolution = depth_resolution
        self.depth_feature_dim = config.get("depth_feature_dim", 130)  # ä»é…ç½®æ–‡ä»¶è·å–æ€»æ·±åº¦ç‰¹å¾ç»´åº¦
        self.formation_distance = formation_distance
        self.max_steps = max_steps
        self.success_radius_xy = success_radius_xy
        self.success_height_tol = success_height_tol
        self.catchup_gain_pos = catchup_gain_pos
        self.catchup_gain_pos_z = catchup_gain_pos_z
        self.catchup_gain_speed = catchup_gain_speed
        self.catchup_speed_target = catchup_speed_target
        self.catchup_max_force_xy = catchup_max_force_xy
        self.catchup_max_force_z = catchup_max_force_z
        self.dt = dt
        self.leader_index = 0
        self.enable_formation_force = enable_formation_force
        
        # è®­ç»ƒé˜¶æ®µæ§åˆ¶: 1=leaderå¯¼èˆªè®­ç»ƒ, 2=å®Œæ•´ç¼–é˜Ÿè®­ç»ƒ
        self.training_stage = training_stage
        
        # æ–°å¢ï¼šç›¸æœºé…ç½®å‚æ•°
        self.enable_fixed_overhead_camera = enable_fixed_overhead_camera
        self.fixed_camera_height = fixed_camera_height
        self.fixed_camera_pitch = fixed_camera_pitch

        # ç‰©ç†ä¸–ç•Œ
        self.client = p.connect(config['display'])
        p.setAdditionalSearchPath(pybullet_data.getDataPath())
        
        # é…ç½®ç‰©ç†å¼•æ“ï¼Œå‡å°‘æ—‹è½¬æ•ˆåº”
        p.setPhysicsEngineParameter(
            fixedTimeStep=self.dt,
            numSolverIterations=50,  # å¢åŠ æ±‚è§£è¿­ä»£æ¬¡æ•°æé«˜ç¨³å®šæ€§
            numSubSteps=8,  # å¢åŠ å­æ­¥éª¤æ•°é‡ï¼Œæé«˜æ¨¡æ‹Ÿç²¾åº¦
            enableConeFriction=1,  # å¯ç”¨åœ†é”¥æ‘©æ“¦
            restitutionVelocityThreshold=0.05,  # è°ƒä½åå¼¹é€Ÿåº¦é˜ˆå€¼
            contactERP=0.8,  # å¢å¤§æ¥è§¦é”™è¯¯å‡å°‘å‚æ•°ï¼Œå‡å°éœ‡è¡
            frictionERP=0.8,  # å¢å¤§æ‘©æ“¦é”™è¯¯å‡å°‘å‚æ•°ï¼Œå‡å°éœ‡è¡
            physicsClientId=self.client
        )
        
        # è®¾ç½®é‡åŠ›å¾ˆå°ï¼Œå‡å°‘æ—‹è½¬ç§¯ç´¯å½±å“
        p.setGravity(0, 0, -9.8, physicsClientId=self.client)

        # åˆå§‹åŒ–ç®¡ç†æ¨¡å—
        self.reward_calculator = RewardCalculator(create_default_reward_config())
        
        # åˆ›å»ºä¸ç›¸æœºåƒç´ ä¸€è‡´çš„çŠ¶æ€é…ç½®
        state_config = create_default_state_config()
        state_config['depth_height'] = self.camera_pixel
        state_config['depth_width'] = self.camera_pixel
        state_config['cnn_feature_dim'] = 128  # CNNç‰¹å¾ç»´åº¦
        self.state_processor = StateProcessor(state_config)
        
        self.environment_manager = EnvironmentManager(self.client, create_default_environment_config())
        
        # åˆ›å»ºä¸ç›¸æœºåƒç´ ä¸€è‡´çš„ç›¸æœºé…ç½®
        camera_config = create_default_camera_config()
        camera_config['depth_width'] = self.camera_pixel
        camera_config['depth_height'] = self.camera_pixel
        # æ ¹æ®æ„é€ å‡½æ•°å‚æ•°é…ç½®å›ºå®šä¿¯è§†æ‘„åƒå¤´
        camera_config['fixed_overhead_camera'] = self.enable_fixed_overhead_camera
        camera_config['fixed_camera_height'] = self.fixed_camera_height
        camera_config['fixed_camera_pitch'] = self.fixed_camera_pitch
        self.camera_manager = CameraManager(self.client, camera_config)
        
        # CNNç‰¹å¾ç»´åº¦ + 3ä¸ªé¢å¤–ç‰¹å¾
        depth_features_dim = 128 + 3
        
        self.observation_manager = ObservationSpaceManager(create_default_observation_config(
            num_agents=self.num_drones, 
            depth_features_dim=depth_features_dim,
            use_cnn_features=True,
            cnn_feature_dim=128
        ))
        
        # æ·±åº¦éšœç¢å¤„ç†å™¨å’ŒåŠ¨ä½œæ˜ å°„å™¨
        self.depth_obstacle_processor = DepthObstacleProcessor(
            depth_image_size=(self.camera_pixel, self.camera_pixel),
            collision_threshold=config.get('collision_distance', 0.8) / config.get('depth_scale', 4.0),  # ä½¿ç”¨configä¸­çš„collision_distance
            depth_scale=config.get('depth_scale', 4.0),     # ä»configè¯»å–
            max_depth=config.get('max_depth', 2.0),       # ä»configè¯»å–
            cnn_feature_dim=config.get('cnn_feature_dim', 128)
        )
        
        # è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´
        # æ ¹æ®è®­ç»ƒé˜¶æ®µè®¾ç½®è§‚æµ‹ç©ºé—´
        if self.training_stage == 1:
            # ç¬¬ä¸€é˜¶æ®µï¼šåªè®­ç»ƒé¢†èˆªè€…ï¼Œä½¿ç”¨å•ä¸ªæ™ºèƒ½ä½“çš„è§‚æµ‹ç©ºé—´
            single_agent_config = create_default_observation_config(
                num_agents=1,  # åªä¸ºé¢†èˆªè€…åˆ›å»ºè§‚æµ‹ç©ºé—´
                depth_features_dim=depth_features_dim,
                use_cnn_features=True,
                cnn_feature_dim=128,
                enforce_planar=self.enforce_planar  # ä¼ é€’å¹³é¢æ¨¡å¼å‚æ•°
            )
            single_agent_manager = ObservationSpaceManager(single_agent_config)
            self.observation_space = single_agent_manager.get_observation_space()
            
            # ç¬¬ä¸€é˜¶æ®µï¼šåªæ§åˆ¶é¢†èˆªè€…ï¼ŒåŠ¨ä½œç©ºé—´ä¸º2ç»´ [thrust, torque] - å‰è¿›/åé€€åŠ›å’Œè½¬å‘æ‰­çŸ©
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨åŠ›é™åˆ¶ï¼Œæé«˜é£è¡Œé€Ÿåº¦
            act_high = np.array([config['thrust_upper_bound'], config['torque_upper_bound']], dtype=np.float32)
            act_low = np.array([config['thrust_lower_bound'], config['torque_lower_bound']], dtype=np.float32)
            self.action_space = gym.spaces.Box(act_low, act_high, dtype=np.float32)
        else:
            # ç¬¬äºŒé˜¶æ®µï¼šå®Œæ•´ç¼–é˜Ÿè®­ç»ƒï¼Œä½¿ç”¨æ‰€æœ‰æ™ºèƒ½ä½“çš„è§‚æµ‹ç©ºé—´
            self.observation_space = self.observation_manager.get_observation_space()
            
            # ç¬¬äºŒé˜¶æ®µï¼šæ§åˆ¶æ‰€æœ‰æ— äººæœºï¼Œæ¯æ¶æ— äººæœº3ç»´åŠ¨ä½œ [thrust_forward, thrust_lateral, thrust_z]
            # thrust_forward: å‰è¿›æ¨åŠ›ï¼ˆæœºå¤´åæ ‡ç³»ï¼‰ï¼Œthrust_lateral: ä¾§å‘æ¨åŠ›ï¼Œthrust_z: å‚ç›´æ¨åŠ›
            # ä»configè¯»å–åŠ¨ä½œç©ºé—´é™åˆ¶
            act_high_single = np.array([config['thrust_x_upper_bound'], 
                                       config['thrust_y_upper_bound'], 
                                       config['thrust_z_upper_bound']], dtype=np.float32)
            act_high = np.tile(act_high_single, self.num_drones)
            act_low_single = np.array([config['thrust_x_lower_bound'], 
                                      config['thrust_y_lower_bound'], 
                                      config['thrust_z_lower_bound']], dtype=np.float32)
            act_low = np.tile(act_low_single, self.num_drones)
            self.action_space = gym.spaces.Box(act_low, act_high, dtype=np.float32)

        # è®¾ç½®ç‰©ç†ä¸–ç•Œ
        self.environment_manager.setup_physics_world(self.dt, self.enforce_planar)

        # çŠ¶æ€å˜é‡
        self.goal = None
        self.goal_id = None
        self.drones = []
        self.current_step = 0
        self.success = False
        self.leader_rgb_image = None
        self.leader_depth_image = None

        # åˆå§‹åŒ– (è°ƒç”¨ reset åˆ›å»ºåœºæ™¯/æ— äººæœº/ç›®æ ‡)
        self.reset()




    def _get_formation_positions(self) -> List[np.ndarray]:
        """è·å–ç¼–é˜ŸæœŸæœ›ä½ç½®ï¼ˆè€ƒè™‘ç›®æ ‡æœå‘ï¼‰"""
        if self.goal is None:
            return [np.zeros(3) for _ in range(self.num_drones)]

        leader_pos, _ = p.getBasePositionAndOrientation(self.drones[self.leader_index].drone, self.client)
        leader_pos = np.array(leader_pos)
        
        # è®¡ç®—é¢†èˆªæœºæœå‘ç›®æ ‡çš„æ–¹å‘
        vec = np.array(self.goal) - leader_pos
        yaw = math.atan2(vec[1], vec[0]) if np.linalg.norm(vec[:2]) > 1e-6 else 0.0
        cy, sy = math.cos(yaw), math.sin(yaw)
        rot = np.array([[cy,-sy,0],[sy,cy,0],[0,0,1]])
        
        # æ–¹å½¢ç¼–é˜Ÿæ¨¡å¼
        body_offsets = [
            np.array([0, 0, 0]),  # é¢†èˆªè€…
            np.array([self.formation_distance, self.formation_distance, 0]),
            np.array([self.formation_distance, -self.formation_distance, 0]),
            np.array([-self.formation_distance, self.formation_distance, 0]),
            np.array([-self.formation_distance, -self.formation_distance, 0])
        ]
        
        return [leader_pos + rot @ offset for offset in body_offsets[:self.num_drones]]

    def reset(self, *, seed: int | None = None, options: Dict[str, Any] | None = None):
        """é‡ç½®ç¯å¢ƒ"""
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)

        p.resetSimulation(self.client)
        
        # è®¾ç½®ç‰©ç†ä¸–ç•Œ
        self.environment_manager.setup_physics_world(self.dt, self.enforce_planar)

        # ç”Ÿæˆç¯å¢ƒ
        env_info = self.environment_manager.generate_environment()

        # é‡‡æ ·ç›®æ ‡
        self.goal = self.environment_manager.sample_goal()
        self.goal_id = self.environment_manager.create_goal_object(self.goal)

        # åˆ›å»ºæ— äººæœº
        self.drones = [Drone(self.client) for _ in range(self.num_drones)]

        # è®¾ç½®æ— äººæœºèµ·å§‹ä½ç½®
        self.environment_manager.set_drone_start_positions(self.drones, self.num_drones)
        
        # è®°å½•èµ·å§‹ä½ç½®ï¼Œç”¨äºè®¡ç®—è·èµ·ç‚¹çš„è·ç¦»
        leader_pos, _ = p.getBasePositionAndOrientation(self.drones[self.leader_index].drone, self.client)
        self.start_position = np.array(leader_pos)
        self.max_traveled_distance = 0.0  # è®°å½•æœ€è¿œç§»åŠ¨è·ç¦»

        # è®¾ç½®é¢†èˆªè€…ç›¸æœº
        if self.use_leader_camera:
            # å¯ç”¨åˆæˆç›¸æœºè§†å›¾æ˜¾ç¤º
            self.camera_manager.enable_synthetic_camera_views()

        # é‡ç½®çŠ¶æ€
        self.current_step = 0
        self.success = False
        
        # é‡ç½®å¤„ç†æ¨¡å—
        self.reward_calculator.reset_state()
        self.camera_manager.cleanup()

        # æ¸²æŸ“ç¯å¢ƒ
        self.render()

        obs = self._build_observation()
        return obs, {}

    def _leader_goal_distance(self) -> float:
        """è®¡ç®—é¢†èˆªè€…åˆ°ç›®æ ‡è·ç¦»"""
        if self.goal is None:
            return 0.0
        leader_pos, _ = p.getBasePositionAndOrientation(self.drones[self.leader_index].drone, self.client)
        return float(np.linalg.norm(np.array(leader_pos) - np.array(self.goal)))

    def _build_observation(self) -> np.ndarray:
        """æ„å»ºè§‚æµ‹ - ä½¿ç”¨å°è£…çš„çŠ¶æ€å¤„ç†å™¨"""
        observations = []
        
        # è·å–é¢†èˆªè€…æ·±åº¦å›¾åƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
        leader_depth_image = None
        if self.use_leader_camera:
            leader_depth_image = self.get_leader_depth_image()
        
        # ä¸ºæ¯ä¸ªæ— äººæœºæ„å»ºè§‚æµ‹
        for i in range(self.num_drones):
            pos, quat = p.getBasePositionAndOrientation(self.drones[i].drone, self.client)
            vel, _ = p.getBaseVelocity(self.drones[i].drone, self.client)
            pos = np.array(pos)
            quat = np.array(quat)
            vel = np.array(vel)
            
            # ä½¿ç”¨çŠ¶æ€å¤„ç†å™¨æ„å»ºçŠ¶æ€
            if i == self.leader_index:
                # é¢†èˆªè€…ä½¿ç”¨æ·±åº¦ä¿¡æ¯
                obs = self.state_processor.build_state(
                    drone_id=i,
                    position=pos,
                    velocity=vel,
                    orientation=quat,
                    target_position=np.array(self.goal),
                    depth_image=leader_depth_image,
                    enforce_planar=self.enforce_planar  # ä¼ é€’å¹³é¢æ¨¡å¼å‚æ•°
                )
            else:
                # è·Ÿéšè€…ä¸ä½¿ç”¨æ·±åº¦ä¿¡æ¯
                obs = self.state_processor.build_state(
                    drone_id=i,
                    position=pos,
                    velocity=vel,
                    orientation=quat,
                    target_position=np.array(self.goal),
                    depth_image=None,
                    enforce_planar=self.enforce_planar  # ä¼ é€’å¹³é¢æ¨¡å¼å‚æ•°
                )
            
            observations.append(obs)
        
        # ç»„åˆæ‰€æœ‰è§‚æµ‹
        # ç¬¬ä¸€é˜¶æ®µè®­ç»ƒï¼šåªè¿”å›é¢†èˆªè€…è§‚æµ‹
        if self.training_stage == 1:
            final_obs = observations[self.leader_index].astype(np.float32)
        else:
            final_obs = np.concatenate(observations).astype(np.float32)
        
        # ğŸ”¥ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ï¼šç¡®ä¿è§‚æµ‹å€¼ä¸åŒ…å«NaNæˆ–æ— ç©·å€¼
        if np.any(np.isnan(final_obs)) or np.any(np.isinf(final_obs)):
            print(f"âš ï¸  è­¦å‘Š: è§‚æµ‹å€¼åŒ…å«NaNæˆ–æ— ç©·å€¼ï¼Œæ­£åœ¨ä¿®å¤...")
            # æ›¿æ¢NaNä¸º0ï¼Œæ›¿æ¢æ— ç©·å€¼ä¸ºæœ‰é™å€¼
            final_obs = np.nan_to_num(final_obs, nan=0.0, posinf=10.0, neginf=-10.0)
            print(f"âœ… å·²ä¿®å¤è§‚æµ‹å€¼ï¼ŒèŒƒå›´: [{final_obs.min():.3f}, {final_obs.max():.3f}]")
        
        return final_obs


    def get_leader_depth_image(self):
        """è·å–é¢†èˆªè€…ç›¸æœºæ·±åº¦å›¾åƒï¼ˆç”¨äºé¿éšœï¼‰"""
        if hasattr(self, 'leader_depth_image'):
            return self.leader_depth_image
        else:
            cam_pos, cam_orn = self.drones[self.leader_index].get_camera_pose()
            _, depth_image = self.camera_manager.get_leader_camera_image_by_pose(cam_pos, cam_orn)
            return depth_image

    def _apply_formation_forces(self):
        """åº”ç”¨ç¼–é˜Ÿè¾…åŠ©åŠ›æ§åˆ¶ï¼ˆä»…è·Ÿéšè€…ï¼‰"""
        if not self.enable_formation_force or self.goal is None:
            return
            
        leader_pos, _ = p.getBasePositionAndOrientation(self.drones[self.leader_index].drone, self.client)
        leader_vel, _ = p.getBaseVelocity(self.drones[self.leader_index].drone, self.client)
        leader_pos = np.array(leader_pos)
        leader_speed = np.linalg.norm(np.array(leader_vel)[:2])

        formation_positions = self._get_formation_positions()

        # åªå¯¹è·Ÿéšè€…æ–½åŠ ç¼–é˜Ÿè¾…åŠ©åŠ›ï¼ˆä¸æ§åˆ¶é¢†èˆªè€…ï¼‰
        for i in range(1, self.num_drones):
            pos, _ = p.getBasePositionAndOrientation(self.drones[i].drone, self.client)
            vel, _ = p.getBaseVelocity(self.drones[i].drone, self.client)
            pos = np.array(pos)
            vel = np.array(vel)
            slot = formation_positions[i]

            # ä½ç½®è¯¯å·®åŠ›
            err = slot - pos
            lateral = err.copy()
            lateral[2] = 0
            force = self.catchup_gain_pos * lateral

            # å‚ç›´è¯¯å·®åŠ›
            if not self.enforce_planar:
                force[2] = self.catchup_gain_pos_z * err[2]
            else:
                force[2] = 0.0

            # é€Ÿåº¦åŒæ­¥åŠ›
            leader_dir = np.array(leader_vel)
            leader_dir[2] = 0
            if np.linalg.norm(leader_dir) > 1e-3:
                ld = leader_dir / np.linalg.norm(leader_dir)
                speed_i = np.linalg.norm(vel[:2])
                target = min(self.catchup_speed_target, leader_speed + 0.5)
                deficit = target - speed_i
                if deficit > 0:
                    force += self.catchup_gain_speed * deficit * ld

            # é™åˆ¶åŠ›çš„å¤§å°
            force[:2] = np.clip(force[:2], -self.catchup_max_force_xy, self.catchup_max_force_xy)
            force[2] = np.clip(force[2], -self.catchup_max_force_z, self.catchup_max_force_z)

            p.applyExternalForce(self.drones[i].drone, -1, force.tolist(), [0,0,0], p.WORLD_FRAME, physicsClientId=self.client)

    def _apply_drone_action(self, drone_idx, action):
        # å¦‚æœç¦ç”¨ç¼–é˜ŸåŠ›ä¸”æ˜¯è·Ÿéšè€…ï¼Œåˆ™ä¿æŒé™æ­¢
        if hasattr(self, 'enable_formation_force') and not self.enable_formation_force and drone_idx > 0:
            # é‡ç½®é€Ÿåº¦ä¿æŒé™æ­¢
            p.resetBaseVelocity(self.drones[drone_idx].drone, [0, 0, 0], [0, 0, 0], physicsClientId=self.client)
        else:
            # ã€ç®€åŒ–ã€‘åªè´Ÿè´£è°ƒç”¨æ— äººæœºçš„åŸºæœ¬åŠ¨ä½œï¼ˆæ¨åŠ›å’Œæ‰­çŸ©ï¼‰ï¼Œä¸å¤„ç†é‡åŠ›è¡¥å¿
            self.drones[drone_idx].apply_action(action, apply_gravity_compensation=False)
            
            # ã€ç»Ÿä¸€ã€‘é‡åŠ›è¡¥å¿ç»Ÿä¸€åœ¨æ­¤å¤„å¤„ç†
            if not self.enforce_planar:
                # 3Dæ¨¡å¼ï¼šæä¾›å®Œæ•´é‡åŠ›è¡¥å¿
                drone_mass = p.getDynamicsInfo(self.drones[drone_idx].drone, -1, physicsClientId=self.client)[0]
                gravity_compensation = drone_mass * 9.8
                p.applyExternalForce(self.drones[drone_idx].drone, -1, [0, 0, gravity_compensation], [0, 0, 0], p.WORLD_FRAME, physicsClientId=self.client)
            # å¹³é¢æ¨¡å¼ï¼šä¸æä¾›é‡åŠ›è¡¥å¿ï¼ˆå› ä¸ºPyBulleté‡åŠ›è®¾ä¸º0ï¼‰
            
            # æ³¨æ„ï¼šå¹³é¢æ¨¡å¼é€Ÿåº¦é‡ç½®å·²ç§»è‡³stepæ–¹æ³•æœ«å°¾ï¼Œåœ¨ç‰©ç†ä»¿çœŸä¹‹åè¿›è¡Œ

    def _compute_reward(self) -> Tuple[float, Dict[str, float], bool]:
        """è®¡ç®—å¥–åŠ± - ä½¿ç”¨å°è£…çš„å¥–åŠ±è®¡ç®—å™¨"""
        done = False
        
        # è·å–é¢†èˆªè€…çŠ¶æ€
        leader_pos, leader_quat = p.getBasePositionAndOrientation(self.drones[self.leader_index].drone, self.client)
        leader_pos = np.array(leader_pos)
        leader_vel, leader_ang_vel = p.getBaseVelocity(self.drones[self.leader_index].drone, self.client)
        leader_vel = np.array(leader_vel)
        leader_ang_vel = np.array(leader_ang_vel)
        
        # æ£€æŸ¥æˆåŠŸæ¡ä»¶
        success = self._check_success()
        self.success = success  # è®¾ç½®å®ä¾‹å˜é‡ï¼Œç¡®ä¿stepæ–¹æ³•èƒ½è¿”å›æ­£ç¡®çš„æˆåŠŸçŠ¶æ€
        
        # è·å–æ·±åº¦ä¿¡æ¯ï¼ˆåŒ…å«ç¢°æ’ä¿¡æ¯ï¼‰
        depth_info = self._get_depth_info()
        
        # ä¸ºé¿éšœå¥–åŠ±è®¡ç®—æ·»åŠ é€Ÿåº¦ä¿¡æ¯
        depth_info['velocity'] = np.linalg.norm(leader_vel[:2])  # å¹³é¢é€Ÿåº¦
        depth_info['angular_velocity'] = leader_ang_vel[2]  # åèˆªè§’é€Ÿåº¦
        
        # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶ï¼šæˆåŠŸã€è¶…æ—¶ã€æˆ–ç¢°æ’
        collision_occurred = depth_info.get('collision', False)
        done = success or self.current_step >= self.max_steps or collision_occurred
        
        # ğŸ¯ ä½¿ç”¨æç®€å¥–åŠ±è®¡ç®—å™¨ï¼ˆ4ç»„ä»¶æ— å†—ä½™è®¾è®¡ï¼‰
        # ç»„ä»¶: success(+2000) + crash(-1500) + navigation(~1.5/step) + safe_navigation(~0.5/step)
        total_reward, reward_details = self.reward_calculator.compute_total_reward(
            drone_id="leader",
            position=leader_pos,
            target_position=np.array(self.goal),
            velocity=leader_vel,
            depth_info=depth_info,
            orientation=leader_quat,  # æœå‘ä¿¡æ¯ï¼ˆç”¨äºnavigationçš„å¯¹é½å¥–åŠ±ï¼‰
            formation_info=None,  # å¯ä»¥åç»­æ·»åŠ ç¼–é˜Ÿä¿¡æ¯
            done=done,
            success=success,
            current_step=0  # æç®€ç³»ç»Ÿä¸ä½¿ç”¨æ­¥æ•°æƒ©ç½šï¼Œä¼ 0å³å¯
        )
        
        return total_reward, reward_details, done
    
    def _get_depth_info(self) -> Dict[str, float]:
        """è·å–æ·±åº¦ä¿¡æ¯å’Œç¢°æ’ä¿¡æ¯"""
        depth_info = {'min_depth': float('inf'), 'mean_depth': 3.0, 'forward_min': 3.0, 'left_min': 3.0, 'right_min': 3.0}
        
        # æ·»åŠ ç¢°æ’æ£€æµ‹ä¿¡æ¯
        collision_info = self._check_collision()
        depth_info['collision'] = collision_info['collision']
        depth_info['collision_type'] = collision_info['collision_type']
        depth_info['contact_points'] = collision_info['contact_points']
        
        # æ·»åŠ ä½ç½®ä¿¡æ¯å’Œåˆ°èµ·ç‚¹çš„è·ç¦»
        leader_pos, _ = p.getBasePositionAndOrientation(self.drones[self.leader_index].drone, self.client)
        distance_from_start = np.linalg.norm(np.array(leader_pos) - self.start_position)
        depth_info['distance_to_start'] = float(distance_from_start)  # å½“å‰è·èµ·ç‚¹è·ç¦»
        depth_info['max_traveled_distance'] = float(self.max_traveled_distance)  # æœ€è¿œç§»åŠ¨è·ç¦»
        depth_info['current_step'] = self.current_step  # æ·»åŠ å½“å‰æ­¥æ•°ä¿¡æ¯
        
        if self.use_leader_camera:
            # ä½¿ç”¨å±è”½åçš„æ·±åº¦å›¾åƒè¿›è¡Œå¥–åŠ±è®¡ç®—ï¼Œé¿å…è‡ªé®æŒ¡å½±å“
            depth_image = self._get_masked_leader_depth()
            if depth_image is not None and depth_image.size > 0:
                # é¢„å¤„ç†æ·±åº¦å›¾åƒ
                raw_depth = depth_image if len(depth_image.shape) == 2 else depth_image[:, :, 0]
                depth_map = self.state_processor.depth_processor.preprocess_depth_image(raw_depth)
                
                # ä¿å­˜æ·±åº¦å›¾åƒç”¨äºé¿éšœå¥–åŠ±è®¡ç®—
                depth_info['depth_map'] = depth_map
                
                h, w = depth_map.shape
                
                # è®¡ç®—å„åŒºåŸŸæ·±åº¦
                regions = {
                    'center': depth_map[h//4:3*h//4, w//4:3*w//4],
                    'forward': depth_map[h//3:2*h//3, w//3:2*w//3],
                    'left': depth_map[h//4:3*h//4, :w//3],
                    'right': depth_map[h//4:3*h//4, 2*w//3:]
                }
                
                # è®¡ç®—ä¸­å¿ƒåŒºåŸŸæ·±åº¦
                valid_depths = regions['center'][regions['center'] > 0.1]
                if len(valid_depths) > 0:
                    depth_info['min_depth'] = float(np.min(valid_depths))
                    depth_info['mean_depth'] = float(np.mean(valid_depths))
                
                # è®¡ç®—å„æ–¹å‘æœ€å°æ·±åº¦
                for name, region in regions.items():
                    if name == 'center':
                        continue
                    valid = region[region > 0.1]
                    if len(valid) > 0:
                        depth_info[f"{name}_min"] = float(np.min(valid))
        
        return depth_info
    
    def _check_success(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æˆåŠŸåˆ°è¾¾ç›®æ ‡ - å¹³é¢æ¨¡å¼åªæ£€æŸ¥æ°´å¹³è·ç¦»"""
        if self.goal is None:
            return False
            
        leader_pos, _ = p.getBasePositionAndOrientation(self.drones[self.leader_index].drone, self.client)
        leader_pos = np.array(leader_pos)
        
        horiz_dist = np.linalg.norm(np.array(self.goal)[:2] - leader_pos[:2])
        
        # å¹³é¢æ¨¡å¼ï¼šåªæ£€æŸ¥æ°´å¹³è·ç¦»ï¼Œä¸æ£€æŸ¥é«˜åº¦
        if self.enforce_planar:
            return horiz_dist < self.success_radius_xy
        else:
            # 3Dæ¨¡å¼ï¼šæ£€æŸ¥æ°´å¹³è·ç¦»å’Œé«˜åº¦å·®
            height_diff = abs(self.goal[2] - leader_pos[2])
            return horiz_dist < self.success_radius_xy and height_diff < self.success_height_tol

    def _check_collision(self, drone_idx: int = None) -> Dict[str, any]:
        """
        æ£€æŸ¥ç¢°æ’ - ä½¿ç”¨PyBulletæ¥è§¦ç‚¹æ£€æµ‹ï¼ˆå‚è€ƒå•æ— äººæœºæ–¹æ³•ï¼‰
        
        Args:
            drone_idx: æ£€æŸ¥çš„æ— äººæœºç´¢å¼•ï¼ŒNoneè¡¨ç¤ºæ£€æŸ¥é¢†èˆªè€…
            
        Returns:
            DictåŒ…å«: collision (bool), contact_points (int), collision_type (str), position (list)
        """
        if drone_idx is None:
            drone_idx = self.leader_index
            
        collision_info = {
            'collision': False,
            'contact_points': 0,
            'collision_type': 'none',
            'position': [0, 0, 0]
        }
        
        # è·å–æ— äººæœºä½ç½®
        drone_pos, _ = p.getBasePositionAndOrientation(self.drones[drone_idx].drone, self.client)
        collision_info['position'] = list(drone_pos)
        
        # 1. PyBulletæ¥è§¦ç‚¹æ£€æµ‹ï¼ˆæœ€å‡†ç¡®çš„ç‰©ç†ç¢°æ’ï¼‰
        contact_points = p.getContactPoints(self.drones[drone_idx].drone, physicsClientId=self.client)
        if contact_points:
            # è¿‡æ»¤ä¸ç›®æ ‡å¯¹è±¡çš„ç¢°æ’ - æ¥è§¦ç›®æ ‡ä¸ç®—ç¢°æ’
            valid_contacts = []
            for contact in contact_points:
                contact_object_id = contact[2]  # bodyUniqueIdB
                # å¦‚æœæ¥è§¦çš„æ˜¯ç›®æ ‡å¯¹è±¡ï¼Œä¸ç®—ç¢°æ’
                if hasattr(self, 'goal_id') and self.goal_id is not None and contact_object_id == self.goal_id:
                    continue  # è·³è¿‡ä¸ç›®æ ‡çš„æ¥è§¦
                valid_contacts.append(contact)
            
            if valid_contacts:  # åªæœ‰éç›®æ ‡çš„ç¢°æ’æ‰ç®—çœŸæ­£çš„ç¢°æ’
                collision_info['collision'] = True
                collision_info['contact_points'] = len(valid_contacts)
                collision_info['collision_type'] = 'physical_contact'
                if config.get('debug_collision', False):
                    print(f"è°ƒè¯•: æ£€æµ‹åˆ°ç‰©ç†ç¢°æ’ï¼Œæ¥è§¦ç‚¹æ•°: {len(valid_contacts)}")
                return collision_info
        
        # 2. è¾¹ç•Œæ£€æµ‹ - å¹³é¢æ¨¡å¼ä¸‹ä¸æ£€æŸ¥é«˜åº¦è¾¹ç•Œ
        if self.enforce_planar:
            # å¹³é¢æ¨¡å¼ï¼šåªæ£€æŸ¥x-yè¾¹ç•Œ
            if abs(drone_pos[0]) > 18.0 or abs(drone_pos[1]) > 18.0:  # ä»14.5å¢åŠ åˆ°18.0ç±³
                collision_info['collision'] = True
                collision_info['collision_type'] = 'boundary'
                return collision_info
        else:
            # 3Dæ¨¡å¼ï¼šæ£€æŸ¥æ‰€æœ‰è¾¹ç•Œ
            if (abs(drone_pos[0]) > 18.0 or abs(drone_pos[1]) > 18.0 or  # ä»14.5å¢åŠ åˆ°18.0ç±³
                drone_pos[2] < 0.3 or drone_pos[2] > 2.4):
                collision_info['collision'] = True
                collision_info['collision_type'] = 'boundary'
                return collision_info
        
        return collision_info

    def step(self, action: np.ndarray):
        """æ‰§è¡Œä¸€æ­¥"""
        action = np.asarray(action, dtype=np.float32)
        
        if self.training_stage == 1:
            # ç¬¬ä¸€é˜¶æ®µï¼šåŠ¨ä½œæ˜¯é¢†èˆªè€…çš„2ç»´åŠ¨ä½œ [thrust, torque] - å‰è¿›/åé€€åŠ›å’Œè½¬å‘æ‰­çŸ©
            if action.shape[0] != 2:
                raise ValueError(f"ç¬¬ä¸€é˜¶æ®µåŠ¨ä½œç»´åº¦é”™è¯¯ï¼šæœŸæœ›2ç»´åŠ¨ä½œ(é¢†èˆªè€…)ï¼Œå®é™…æ”¶åˆ° {action.shape[0]}ç»´ã€‚è¯·æ£€æŸ¥åŠ¨ä½œç”Ÿæˆé€»è¾‘ï¼")
            
            # åº”ç”¨é¢†èˆªè€…åŠ¨ä½œ
            self._apply_drone_action(0, action)
            
            # è·Ÿéšè€…ä¿æŒé™æ­¢ï¼ˆé‡åŠ›è¡¥å¿ï¼‰
            for i in range(1, self.num_drones):
                self._apply_drone_action(i, np.zeros(2, dtype=np.float32))
                
        else:
            # ç¬¬äºŒé˜¶æ®µï¼šè§£æåŠ¨ä½œï¼Œæ‰€æœ‰æ— äººæœºéƒ½æ˜¯3ç»´ [fx, fy, fz] - ä¸–ç•Œåæ ‡ç³»ç›´æ¥åŠ›æ§åˆ¶
            expected_dim = 3 * self.num_drones
            if action.shape[0] != expected_dim:
                raise ValueError(f"ç¬¬äºŒé˜¶æ®µåŠ¨ä½œç»´åº¦é”™è¯¯ï¼šæœŸæœ› {expected_dim}ï¼Œå®é™…æ”¶åˆ° {action.shape[0]}ã€‚è¯·æ£€æŸ¥åŠ¨ä½œç”Ÿæˆé€»è¾‘ï¼")
            
            # åº”ç”¨åŠ¨ä½œåˆ°æ‰€æœ‰æ— äººæœºï¼ˆä¸–ç•Œåæ ‡ç³»ç›´æ¥åŠ›æ§åˆ¶ï¼‰
            for i in range(self.num_drones):
                drone_action = action[i*3:(i+1)*3]  # [fx, fy, fz]
                
                # å¹³é¢æ¨¡å¼ï¼šå¼ºåˆ¶zè½´åŠ¨ä½œä¸º0ï¼Œåªåœ¨x-yå¹³é¢å†…ç§»åŠ¨
                if self.enforce_planar:
                    drone_action = np.array([drone_action[0], drone_action[1], 0.0])
                
                self._apply_drone_action(i, drone_action)

        # ç¼–é˜Ÿè¾…åŠ©åŠ›æ§åˆ¶ï¼ˆä»…è·Ÿéšè€…ï¼Œä¸”ä»…å½“æ— äººæœºæ•°é‡>1æ—¶ï¼‰
        if self.num_drones > 1:
            self._apply_formation_forces()

        # ç‰©ç†ä»¿çœŸ
        p.stepSimulation(self.client)
        
        self.render()
        
        # æ›´æ–°æœ€å¤§ç§»åŠ¨è·ç¦»
        leader_pos, _ = p.getBasePositionAndOrientation(self.drones[self.leader_index].drone, self.client)
        current_distance_from_start = np.linalg.norm(np.array(leader_pos) - self.start_position)
        self.max_traveled_distance = max(self.max_traveled_distance, current_distance_from_start)
        
        self.current_step += 1

        # åœ¨å¹³é¢æ¨¡å¼ä¸‹ï¼Œå¼ºåˆ¶çº¦æŸæ— äººæœºå§¿æ€å’Œè¿åŠ¨
        if self.enforce_planar:
            for i in range(self.num_drones):
                # è·å–ç‰©ç†ä»¿çœŸåçš„é€Ÿåº¦å’Œå§¿æ€
                current_vel, current_ang_vel = p.getBaseVelocity(self.drones[i].drone, self.client)
                _, current_orn = p.getBasePositionAndOrientation(self.drones[i].drone, self.client)
                current_euler = p.getEulerFromQuaternion(current_orn)

                # ã€å…³é”®ä¿®å¤ã€‘ä¸å®Œå…¨é‡ç½®é€Ÿåº¦ï¼Œåªä¿®æ­£çº¦æŸéƒ¨åˆ†
                # ä¿ç•™æ¨åŠ›äº§ç”Ÿçš„xyé€Ÿåº¦ï¼Œåªå¼ºåˆ¶zè½´é€Ÿåº¦ä¸º0
                constrained_vel = [current_vel[0], current_vel[1], 0.0]  # ä¿ç•™xyé€Ÿåº¦ï¼Œz=0

                # å¼ºåˆ¶å§¿æ€ä¸ºæ°´å¹³ï¼ˆåªå…è®¸yawæ—‹è½¬ï¼‰
                constrained_euler = [0.0, 0.0, current_euler[2]]  # [roll=0, pitch=0, yawä¿æŒ]
                constrained_orn = p.getQuaternionFromEuler(constrained_euler)

                # è·å–å½“å‰ä½ç½®
                current_pos, _ = p.getBasePositionAndOrientation(self.drones[i].drone, self.client)

                # é‡ç½®å§¿æ€å’Œéƒ¨åˆ†é€Ÿåº¦
                p.resetBasePositionAndOrientation(self.drones[i].drone, current_pos, constrained_orn, physicsClientId=self.client)

                # åªé‡ç½®è§’é€Ÿåº¦ï¼šå¼ºåˆ¶rollå’Œpitchè§’é€Ÿåº¦ä¸º0ï¼Œä¿ç•™yawè§’é€Ÿåº¦
                constrained_ang_vel = [0.0, 0.0, current_ang_vel[2]]  # [roll_rate=0, pitch_rate=0, yaw_rateä¿æŒ]
                p.resetBaseVelocity(self.drones[i].drone, constrained_vel, constrained_ang_vel, physicsClientId=self.client)

        # è·å–è§‚æµ‹å’Œå¥–åŠ±
        obs = self._build_observation()
        reward, rinfo, done = self._compute_reward()

        truncated = self.current_step >= self.max_steps
        terminated = done

        return obs, reward, terminated, truncated, {"reward_info": rinfo, "success": self.success}

    def render(self, mode="human"):
        """æ¸²æŸ“ç¯å¢ƒ"""
        try:
            # è®¾ç½®è§‚å¯Ÿç›¸æœºè§†è§’
            if self.enable_fixed_overhead_camera:
                self.camera_manager.setup_fixed_overhead_camera(self.drones[self.leader_index])
            else:
                # ä½¿ç”¨é…ç½®çš„ç›¸æœºè®¾ç½®
                camera_config = {
                    'camera_follow': config.get('camera_follow', True),
                    'camera_target': config.get('camera_target', 'leader'),
                    'camera_distance': config.get('camera_distance', 3.0),
                    'camera_yaw': config.get('camera_yaw', 30.0),
                    'camera_pitch': config.get('camera_pitch', -20.0)
                }
                self.camera_manager.update_observer_camera(self.drones, self.leader_index, camera_config)
            
            # æ›´æ–°ä¾§è¾¹æ è°ƒè¯•ç›¸æœº
            if self.use_leader_camera and len(self.drones) > self.leader_index:
                # æ›´æ–°è°ƒè¯•ç›¸æœºæ˜¾ç¤º
                self.camera_manager.update_debug_camera_for_sidebar(self.drones[self.leader_index])
                
                # æ›´æ–°åˆæˆç›¸æœºé¢æ¿ï¼Œå¤„ç†æ©ç æ·±åº¦
                rgb, depth, seg, self_mask = self._get_leader_images_with_mask()
                
                # ä¿å­˜å›¾åƒç”¨äºå…¶ä»–åŠŸèƒ½
                if rgb is not None and depth is not None:
                    self.leader_rgb_image, self.leader_depth_image = rgb, depth
                
                # æ›´æ–°åˆæˆç›¸æœºé¢æ¿æ˜¾ç¤º
                self.camera_manager.update_synthetic_camera_panel(self.drones[self.leader_index])
            
            # æ¸²æŸ“ç›®æ ‡æç¤º
            if self.goal is not None and config.get('render_goal_hint', True):
                self.camera_manager.render_goal_hint(self.drones, self.goal, self.leader_index)
                
        except Exception as e:
            # æ¸²æŸ“å¤±è´¥æ—¶è·³è¿‡ï¼ˆDIRECTæ¨¡å¼ä¸‹å¯èƒ½ä¸æ”¯æŒï¼‰
            pass
        
        return

    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        try:
            p.disconnect(self.client)
        except Exception:
            pass

    def _get_masked_leader_depth(self) -> np.ndarray | None:
        """è·å–å±è”½äº†æ— äººæœºè‡ªèº«çš„æ·±åº¦å›¾åƒï¼Œç”¨äºé¿éšœç®—æ³•"""
        if not self.use_leader_camera:
            return None
        try:
            # è·å–å›¾åƒå’Œæ©ç 
            rgb, depth, seg, self_mask = self._get_leader_images_with_mask()
            
            if depth is None or self_mask is None:
                return depth
                
            # å°†è‡ªèº«åƒç´ çš„æ·±åº¦è®¾ç½®ä¸ºè¿œå¹³é¢ï¼Œé¿å…è‡ªé®æŒ¡
            far_val = float(self.camera_manager.depth_camera_config.get('far_plane', 10.0))
            masked_depth = depth.copy()
            masked_depth[self_mask] = far_val
            return masked_depth
        except Exception as e:
            print(f"è·å–æ©ç æ·±åº¦å›¾åƒå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ·±åº¦: {e}")
            # è¿”å›é»˜è®¤æ·±åº¦
            width = self.camera_manager.depth_camera_config['width']
            height = self.camera_manager.depth_camera_config['height']
            return np.full((height, width), 5.0, dtype=np.float32)
            
    def _get_leader_images_with_mask(self):
        """è·å–é¢†èˆªè€…ç›¸æœºå›¾åƒå’Œæ©ç ä¿¡æ¯ï¼Œé›†ä¸­å¤„ç†è‡ªèº«æ©ç é€»è¾‘"""
        try:
            if not self.use_leader_camera or self.leader_index >= len(self.drones):
                return None, None, None, None
                
            # ä»ç›¸æœºç®¡ç†å™¨è·å–å›¾åƒå’Œæ©ç 
            cam_pos, cam_orn = self.drones[self.leader_index].get_camera_pose()
            rgb, depth, seg = self.camera_manager.get_leader_camera_frame_by_pose(cam_pos, cam_orn)
            
            if seg is None:
                return rgb, depth, None, None
                
            # åˆ›å»ºè‡ªèº«æ©ç 
            leader_body_unique_id = int(self.drones[self.leader_index].drone)
            obj_ids = (seg >> 24).astype(np.int32)
            self_mask = (obj_ids == leader_body_unique_id)
            
            # å±è”½ç›®æ ‡å¯¹è±¡ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(self, 'goal_id') and self.goal_id is not None:
                goal_mask = (obj_ids == self.goal_id)
                self_mask = self_mask | goal_mask
                
            return rgb, depth, seg, self_mask
            
        except Exception as e:
            print(f"è·å–é¢†èˆªè€…å›¾åƒå¤±è´¥: {e}")
            return None, None, None, None
