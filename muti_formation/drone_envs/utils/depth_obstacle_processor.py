"""
æ·±åº¦å›¾åƒå¤„ç†å’Œé¿éšœç‰¹å¾æå–æ¨¡å—
Inspired by "Towards Monocular Vision Based Collision Avoidance Using Deep Reinforcement Learning"
"""
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Tuple, Optional, Dict

class DepthObstacleProcessor:
    """æ·±åº¦å›¾åƒå¤„ç†å’Œé¿éšœç‰¹å¾æå–ç±»"""
    
    def __init__(self, 
                 depth_image_size: Tuple[int, int] = (128, 160),
                 collision_threshold: float = 0.2,
                 depth_scale: float = 4.0,
                 max_depth: float = 2.0,
                 cnn_feature_dim: int = 128):
        """
        åˆå§‹åŒ–æ·±åº¦å¤„ç†å™¨
        
        Args:
            depth_image_size: æ·±åº¦å›¾åƒå°ºå¯¸ (height, width)
            collision_threshold: ç¢°æ’æ£€æµ‹é˜ˆå€¼ (ç±³)
            depth_scale: æ·±åº¦å€¼ç¼©æ”¾å› å­
            max_depth: æœ€å¤§æ·±åº¦å€¼
            cnn_feature_dim: CNNç‰¹å¾ç»´åº¦
        """
        self.height, self.width = depth_image_size
        self.collision_threshold = collision_threshold
        self.depth_scale = depth_scale
        self.max_depth = max_depth
        self.cnn_feature_dim = cnn_feature_dim
        
        # åˆå§‹åŒ–CNNæ¨¡å‹
        self.cnn_model = self._build_cnn_model()
        self.cnn_model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
    def _build_cnn_model(self) -> nn.Module:
        """æ„å»ºé«˜æ•ˆçš„CNNæ·±åº¦ç‰¹å¾æå–æ¨¡å‹"""
        class EfficientDepthCNN(nn.Module):
            def __init__(self, input_channels=1, feature_dim=128):
                super(EfficientDepthCNN, self).__init__()
                
                # å·ç§¯å±‚å®šä¹‰
                self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=2, padding=1)  # 128x160 -> 64x80
                self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)  # 64x80 -> 32x40
                self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)  # 32x40 -> 16x20
                self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)  # 16x20 -> 8x10
                
                # è‡ªé€‚åº”å¹³å‡æ± åŒ–åˆ°å›ºå®šå¤§å°
                self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))  # 8x10 -> 4x4
                
                # å…¨è¿æ¥å±‚
                self.fc = nn.Linear(256 * 4 * 4, feature_dim)
                
                # æ‰¹å½’ä¸€åŒ–
                self.bn1 = nn.BatchNorm2d(32)
                self.bn2 = nn.BatchNorm2d(64)
                self.bn3 = nn.BatchNorm2d(128)
                self.bn4 = nn.BatchNorm2d(256)
                
            def forward(self, x):
                # å·ç§¯å—1
                x = F.relu(self.bn1(self.conv1(x)))
                # å·ç§¯å—2
                x = F.relu(self.bn2(self.conv2(x)))
                # å·ç§¯å—3
                x = F.relu(self.bn3(self.conv3(x)))
                # å·ç§¯å—4
                x = F.relu(self.bn4(self.conv4(x)))
                
                # è‡ªé€‚åº”æ± åŒ–
                x = self.adaptive_pool(x)
                
                # å±•å¹³
                x = x.view(x.size(0), -1)
                
                # å…¨è¿æ¥å±‚
                x = self.fc(x)
                return x
        
        return EfficientDepthCNN(input_channels=1, feature_dim=self.cnn_feature_dim)
        
    def preprocess_depth_image(self, depth_image: np.ndarray) -> np.ndarray:
        """
        é¢„å¤„ç†æ·±åº¦å›¾åƒ
        
        Args:
            depth_image: åŸå§‹æ·±åº¦å›¾åƒ (H, W) æˆ– (H, W, 1)
            
        Returns:
            å¤„ç†åçš„æ·±åº¦å›¾åƒ
        """
        if len(depth_image.shape) == 3:
            depth_image = depth_image[:, :, 0]
        
        # å¤„ç†NaNå€¼å’Œæ— ç©·å€¼
        depth_image = np.array(depth_image, dtype=np.float32)
        depth_image[np.isnan(depth_image)] = 5.0
        depth_image[np.isinf(depth_image)] = 5.0
        
        # å½’ä¸€åŒ–å¤„ç†
        depth_image = depth_image / self.depth_scale
        depth_image = np.clip(depth_image, 0.0, self.max_depth)
        
        return depth_image
        
    def extract_cnn_features(self, depth_map: np.ndarray) -> List[float]:
        """
        ä½¿ç”¨CNNæå–æ·±åº¦å›¾åƒç‰¹å¾
        
        Args:
            depth_map: é¢„å¤„ç†åçš„æ·±åº¦å›¾åƒ
            
        Returns:
            CNNç‰¹å¾å‘é‡
        """
        # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
        if len(depth_map.shape) == 2:
            depth_map = depth_map[np.newaxis, np.newaxis, :, :]  # æ·»åŠ batchå’Œchannelç»´åº¦
        elif len(depth_map.shape) == 3:
            depth_map = depth_map[np.newaxis, :, :, :]  # æ·»åŠ batchç»´åº¦
        else:
            raise ValueError(f"Unsupported depth_map shape: {depth_map.shape}")
        
        # è½¬æ¢ä¸ºtorch tensor
        depth_tensor = torch.from_numpy(depth_map).float()
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            features = self.cnn_model(depth_tensor)
            features = features.squeeze(0).cpu().numpy()
        
        # é˜²å¾¡æ€§ç¼–ç¨‹ï¼šæ£€æŸ¥å¹¶å¤„ç†å¼‚å¸¸å€¼
        features = np.array(features, dtype=np.float32)
        if np.any(np.isnan(features)) or np.any(np.isinf(features)):
            print(f"è­¦å‘Š: CNNç‰¹å¾æå–å‡ºç°NaNæˆ–Infå€¼ï¼Œä½¿ç”¨é›¶å‘é‡æ›¿ä»£")
            features = np.zeros(self.cnn_feature_dim, dtype=np.float32)
        
        # æˆªæ–­æç«¯å€¼
        features = np.clip(features, -10.0, 10.0)
        
        return features.tolist()
    
    def extract_depth_features(self, depth_map: np.ndarray) -> List[float]:
        """
        æå–æ·±åº¦ç‰¹å¾ï¼ˆä½¿ç”¨CNNï¼‰
        
        Args:
            depth_map: é¢„å¤„ç†åçš„æ·±åº¦å›¾åƒ
            
        Returns:
            ç‰¹å¾å‘é‡
        """
        return self.extract_cnn_features(depth_map)
    
    def detect_obstacles(self, depth_map: np.ndarray) -> Tuple[bool, float]:
        """
        éšœç¢ç‰©æ£€æµ‹ - ä¼˜åŒ–ä»¥æ›´å¥½æ£€æµ‹å‰æ–¹å¼€æ”¾ç©ºé—´
        
        Args:
            depth_map: é¢„å¤„ç†åçš„æ·±åº¦å›¾åƒ
            
        Returns:
            (æ˜¯å¦æ£€æµ‹åˆ°éšœç¢ç‰©, æœ€å°æ·±åº¦è·ç¦»)
        """
        # æå–ä¸­å¿ƒåŒºåŸŸè¿›è¡Œéšœç¢ç‰©æ£€æµ‹
        h, w = depth_map.shape
        
        # åŒºåˆ†å‰æ–¹å’Œä¾§é¢åŒºåŸŸ
        forward_region = depth_map[h//3:2*h//3, w//3:2*w//3]  # ä¸­å¿ƒå‰æ–¹åŒºåŸŸ
        full_detection_region = depth_map[h//4:3*h//4, w//4:3*w//4]  # æ•´ä½“æ£€æµ‹åŒºåŸŸ
        
        # è®¡ç®—æœ€å°æ·±åº¦è·ç¦»
        min_depth_forward = np.min(forward_region) if forward_region.size > 0 else float('inf')
        min_depth_full = np.min(full_detection_region) if full_detection_region.size > 0 else float('inf')
        
        # ä½¿ç”¨å‰æ–¹åŒºåŸŸçš„æœ€å°æ·±åº¦ï¼Œé™¤éå®ƒæ˜¯æ— ç©·å¤§
        min_depth = min_depth_forward if min_depth_forward < float('inf') else min_depth_full
        
        # äºŒå€¼åŒ–å¤„ç†æ£€æµ‹éšœç¢ç‰©å¯†åº¦ - ä½¿ç”¨é…ç½®çš„ç¢°æ’é˜ˆå€¼
        obstacle_threshold = self.collision_threshold  # ä½¿ç”¨é…ç½®çš„ç¢°æ’é˜ˆå€¼è€Œä¸æ˜¯ç¡¬ç¼–ç 
        binary_mask = (full_detection_region < obstacle_threshold).astype(np.float32)
        obstacle_density = np.mean(binary_mask)
        
        # ä¸“é—¨æ£€æŸ¥å‰æ–¹æ˜¯å¦å¼€æ”¾ - å¦‚æœå‰æ–¹åŒºåŸŸæœ€å°æ·±åº¦å¤§äºé˜ˆå€¼ï¼Œè®¤ä¸ºå‰æ–¹å¼€æ”¾
        forward_is_open = min_depth_forward > obstacle_threshold
        
        # éšœç¢ç‰©æ£€æµ‹é€»è¾‘ - è°ƒæ•´å¯†åº¦é˜ˆå€¼
        obstacle_detected = obstacle_density > 0.1  # æé«˜é˜ˆå€¼ï¼Œå‡å°‘è¯¯æ£€
            
        return obstacle_detected, float(min_depth)
    
    def get_obstacle_analysis(self, depth_map: np.ndarray) -> Dict[str, float]:
        """
        ğŸ”§ é‡æ„ï¼šåªåšéšœç¢ç‰©åˆ†æï¼Œä¸è®¡ç®—å¥–åŠ±
        
        èŒè´£ï¼šæä¾›å®¢è§‚çš„éšœç¢ç‰©ä¿¡æ¯ï¼Œä¾›RewardCalculatorä½¿ç”¨
        - éšœç¢ç‰©æ£€æµ‹ï¼ˆæ˜¯/å¦ï¼‰
        - æœ€å°è·ç¦»ï¼ˆæ ‡å‡†åŒ–ï¼‰
        - å‰æ–¹å¼€æ”¾åº¦ï¼ˆ0-1ï¼‰
        - ç‰©ç†æœ€å°è·ç¦»ï¼ˆç±³ï¼‰
        
        Args:
            depth_map: é¢„å¤„ç†åçš„æ·±åº¦å›¾åƒ
            
        Returns:
            éšœç¢ç‰©åˆ†æä¿¡æ¯å­—å…¸
        """
        obstacle_detected, min_depth = self.detect_obstacles(depth_map)
        
        # è®¡ç®—ç‰©ç†è·ç¦»
        physical_min_depth = min_depth * self.depth_scale
        
        # è®¡ç®—å‰æ–¹å¼€æ”¾åº¦ï¼ˆ0-1ï¼‰
        h, w = depth_map.shape
        forward_region = depth_map[h//3:2*h//3, w//3:2*w//3]
        forward_openness = np.mean(forward_region * self.depth_scale > 2.0)
        
        # è®¡ç®—å±é™©ç­‰çº§ï¼ˆ0-1ï¼Œ1æœ€å±é™©ï¼‰
        # ğŸ”¥ ä¼˜åŒ–ï¼šæ ¹æ®æœ€å¤§é€Ÿåº¦5m/sè°ƒæ•´è·ç¦»é˜ˆå€¼
        # è€ƒè™‘ååº”æ—¶é—´ï¼š0.5ç§’@5m/s = 2.5ç±³ï¼Œ1ç§’@5m/s = 5ç±³
        danger_level = 0.0
        if physical_min_depth < 1.0:  # <1ç±³ï¼Œéå¸¸å±é™©ï¼ˆ0.2ç§’ååº”æ—¶é—´ï¼‰
            danger_level = 1.0
        elif physical_min_depth < 2.0:  # <2ç±³ï¼Œå±é™©ï¼ˆ0.4ç§’ååº”æ—¶é—´ï¼‰
            danger_level = 0.7
        elif physical_min_depth < 3.0:  # <3ç±³ï¼Œéœ€æ³¨æ„ï¼ˆ0.6ç§’ååº”æ—¶é—´ï¼‰
            danger_level = 0.4
        elif physical_min_depth < 4.0:  # <4ç±³ï¼Œç¨æœ‰é£é™©ï¼ˆ0.8ç§’ååº”æ—¶é—´ï¼‰
            danger_level = 0.2
        
        return {
            'obstacle_detected': bool(obstacle_detected),
            'min_depth': float(min_depth),  # æ ‡å‡†åŒ–æ·±åº¦ [0-2.0]
            'physical_min_depth': float(physical_min_depth),  # ç‰©ç†è·ç¦»ï¼ˆç±³ï¼‰
            'forward_openness': float(forward_openness),  # å‰æ–¹å¼€æ”¾åº¦ [0-1]
            'danger_level': float(danger_level),  # å±é™©ç­‰çº§ [0-1]
            'is_imminent_collision': physical_min_depth <= self.collision_threshold * self.depth_scale
        }
        
    def get_navigation_features(self, depth_map: np.ndarray) -> np.ndarray:
        """
        è·å–å¯¼èˆªç›¸å…³çš„æ·±åº¦ç‰¹å¾
        
        Args:
            depth_map: æ·±åº¦å›¾åƒ
            
        Returns:
            ç‰¹å¾å‘é‡
        """
        # ä½¿ç”¨ç»Ÿä¸€çš„ç‰¹å¾æå–æ¥å£
        depth_features = self.extract_depth_features(depth_map)
        
        # éšœç¢ç‰©æ£€æµ‹ç‰¹å¾
        obstacle_detected, min_depth = self.detect_obstacles(depth_map)
        
        # ç»„åˆç‰¹å¾
        navigation_features = depth_features + [
            float(obstacle_detected),
            min_depth,
        ]
        
        return np.array(navigation_features, dtype=np.float32)
