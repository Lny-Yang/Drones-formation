"""
å¤šæ— äººæœºç¼–é˜Ÿçš„çŠ¶æ€å¤„ç†æ¨¡å—
"""
import numpy as np
import pybullet as p
from typing import Dict, Any, Tuple, List, Optional
from .depth_obstacle_processor import DepthObstacleProcessor

# ç»Ÿä¸€è¯»å–ç¯å¢ƒé…ç½®ï¼Œä¿æŒæ·±åº¦ç¼©æ”¾ç­‰å‚æ•°ä¸€è‡´
try:
    from ..config import multi_drone_env as env_config
except ImportError:
    from drone_envs.config import multi_drone_env as env_config


class StateProcessor:
    """çŠ¶æ€å¤„ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–çŠ¶æ€å¤„ç†å™¨
        
        Args:
            config: çŠ¶æ€é…ç½®å‚æ•°
        """
        self.config = config
        
        # æ·±åº¦å¤„ç†å™¨
        self.depth_processor = DepthObstacleProcessor(
            depth_image_size=(config.get('depth_height', 64), config.get('depth_width', 64)),
            collision_threshold=config.get('collision_threshold', env_config.get('collision_distance', 0.8) / env_config.get('depth_scale', 7.5)),
            depth_scale=config.get('depth_scale', env_config.get('depth_scale', 7.5)),
            max_depth=config.get('max_depth', env_config.get('max_depth', 2.0)),
            cnn_feature_dim=config.get('cnn_feature_dim', env_config.get('cnn_feature_dim', 256))
        )
        
        # çŠ¶æ€ç»´åº¦é…ç½®
        self.position_dim = 3  # x, y, z
        self.velocity_dim = 3  # vx, vy, vz
        self.orientation_dim = 4  # quaternion
        self.target_dim = 3  # target position
        
        # CNNç‰¹å¾ç»´åº¦ + å¢å¼ºç‰¹å¾ç»´åº¦
        self.depth_features_dim = config.get('depth_feature_dim', 130)
        
        # è®¡ç®—æ€»çŠ¶æ€ç»´åº¦
        self.state_dim = (self.position_dim + self.velocity_dim + 
                         self.orientation_dim + self.target_dim + 
                         self.depth_features_dim)
        
        # ç›¸æœºé…ç½®
        self.camera_config = {
            'width': config.get('depth_width', env_config.get('depth_width', 64)),
            'height': config.get('depth_height', env_config.get('depth_height', 64)),
            'fov': config.get('camera_fov', env_config.get('depth_fov', 70.0)),
            'near_plane': config.get('depth_near', env_config.get('depth_near', 0.3)),
            'far_plane': config.get('depth_far', env_config.get('depth_far', 15.0))
        }
        
    def get_state_dimension(self) -> int:
        """è·å–çŠ¶æ€ç»´åº¦"""
        return self.state_dim
    
    def build_state(self, 
                   drone_id: int,
                   position: np.ndarray,
                   velocity: np.ndarray,
                   orientation: np.ndarray,
                   target_position: np.ndarray,
                   depth_image: Optional[np.ndarray] = None,
                   enforce_planar: bool = False) -> np.ndarray:
        """
        æ„å»ºçŠ¶æ€å‘é‡
        
        Args:
            drone_id: æ— äººæœºID
            position: ä½ç½® [x, y, z]
            velocity: é€Ÿåº¦ [vx, vy, vz]
            orientation: å››å…ƒæ•° [x, y, z, w]
            target_position: ç›®æ ‡ä½ç½® [x, y, z]
            depth_image: æ·±åº¦å›¾åƒ
            enforce_planar: æ˜¯å¦å¼ºåˆ¶å¹³é¢æ¨¡å¼ï¼ˆä¸åŒ…å«zè½´ä¿¡æ¯ï¼‰
            
        Returns:
            çŠ¶æ€å‘é‡
        """
        state_components = []
        
        # 1. ä½ç½®ä¿¡æ¯ï¼ˆå½’ä¸€åŒ–ï¼‰
        if enforce_planar:
            # å¹³é¢æ¨¡å¼ï¼šåªä½¿ç”¨x, yä½ç½®
            normalized_position = self._normalize_position_planar(position)
        else:
            normalized_position = self._normalize_position(position)
        state_components.extend(normalized_position)
        
        # 2. é€Ÿåº¦ä¿¡æ¯ï¼ˆå½’ä¸€åŒ–ï¼‰
        if enforce_planar:
            # å¹³é¢æ¨¡å¼ï¼šåªä½¿ç”¨x, yé€Ÿåº¦
            normalized_velocity = self._normalize_velocity_planar(velocity)
        else:
            normalized_velocity = self._normalize_velocity(velocity)
        state_components.extend(normalized_velocity)
        
        # 3. æœå‘ä¿¡æ¯ï¼ˆå››å…ƒæ•°ï¼‰
        state_components.extend(orientation)
        
        # 4. ç›®æ ‡ç›¸å¯¹ä½ç½®ï¼ˆå½’ä¸€åŒ–ï¼‰
        if enforce_planar:
            # å¹³é¢æ¨¡å¼ï¼šåªä½¿ç”¨x, yç›¸å¯¹ä½ç½®
            relative_target = self._compute_relative_target_planar(position, target_position)
        else:
            relative_target = self._compute_relative_target(position, target_position)
        state_components.extend(relative_target)
        
        # 5. æ·±åº¦ç‰¹å¾
        if depth_image is not None:
            depth_features = self._extract_depth_features(depth_image)
        else:
            depth_features = np.zeros(self.depth_features_dim)
        state_components.extend(depth_features)
        
        return np.array(state_components, dtype=np.float32)
    
    def capture_depth_image(self, drone_id: int, position: np.ndarray, orientation: np.ndarray) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        æ•è·æ·±åº¦å›¾åƒå¹¶æå–ä¿¡æ¯
        
        Args:
            drone_id: æ— äººæœºID
            position: ä½ç½®
            orientation: æœå‘ï¼ˆå››å…ƒæ•°ï¼‰
            
        Returns:
            (æ·±åº¦å›¾åƒ, æ·±åº¦ä¿¡æ¯å­—å…¸)
        """
        # å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        rotation_matrix = p.getMatrixFromQuaternion(orientation)
        rotation_matrix = np.array(rotation_matrix).reshape(3, 3)
        
        # è®¡ç®—ç›¸æœºä½ç½®å’Œæœå‘
        camera_position = position + np.array([0, 0, 0.1])  # ç¨å¾®å‘ä¸Šåç§»
        
        # è®¡ç®—ç›®æ ‡ç‚¹ï¼ˆç›¸æœºæœå‘ï¼‰- ä½¿ç”¨Yè½´ä½œä¸ºå‰å‘ï¼Œä¸CameraManagerä¿æŒä¸€è‡´
        forward_vector = rotation_matrix[:, 1]  # Yè½´ä¸ºå‰å‘
        target_position = camera_position + forward_vector * 2.0
        
        # è®¡ç®—ä¸Šå‘é‡
        up_vector = rotation_matrix[:, 2]  # Zè½´ä¸ºä¸Šå‘
        
        # è®¡ç®—è§†å›¾çŸ©é˜µ
        view_matrix = p.computeViewMatrix(
            cameraEyePosition=camera_position,
            cameraTargetPosition=target_position,
            cameraUpVector=up_vector
        )
        
        # è®¡ç®—æŠ•å½±çŸ©é˜µ
        proj_matrix = p.computeProjectionMatrixFOV(
            fov=self.camera_config['fov'],
            aspect=self.camera_config['width'] / self.camera_config['height'],
            nearPlane=self.camera_config['near_plane'],
            farPlane=self.camera_config['far_plane']
        )
        
        # æ¸²æŸ“æ·±åº¦å›¾åƒ
        width = self.camera_config['width']
        height = self.camera_config['height']
        
        _, _, _, depth_buffer, _ = p.getCameraImage(
            width=width,
            height=height,
            viewMatrix=view_matrix,
            projectionMatrix=proj_matrix,
            renderer=p.ER_TINY_RENDERER
        )
        
        # è½¬æ¢æ·±åº¦ç¼“å†²åŒº
        depth_image = self._convert_depth_buffer(depth_buffer)
        
        # å¤„ç†æ·±åº¦å›¾åƒ
        processed_depth = self.depth_processor.preprocess_depth_image(depth_image)
        
        # æå–æ·±åº¦ä¿¡æ¯
        depth_info = self._extract_depth_info(processed_depth)
        
        return processed_depth, depth_info
    
    def _normalize_position_planar(self, position: np.ndarray) -> List[float]:
        """å½’ä¸€åŒ–ä½ç½®ä¿¡æ¯ - å¹³é¢æ¨¡å¼ï¼ˆåªä½¿ç”¨x, yï¼‰"""
        # 30ç±³æˆ¿é—´è¾¹ç•Œï¼š[-15, 15] x [-15, 15]
        normalized = [
            np.clip(position[0] / 15.0, -1.0, 1.0),
            np.clip(position[1] / 15.0, -1.0, 1.0)
        ]
        return normalized
    
    def _normalize_velocity_planar(self, velocity: np.ndarray) -> List[float]:
        """å½’ä¸€åŒ–é€Ÿåº¦ä¿¡æ¯ - å¹³é¢æ¨¡å¼ï¼ˆåªä½¿ç”¨x, yï¼‰"""
        # å‡è®¾æœ€å¤§é€Ÿåº¦ä¸º 5 m/s
        max_velocity = 5.0
        normalized = [
            np.clip(velocity[0] / max_velocity, -1.0, 1.0),
            np.clip(velocity[1] / max_velocity, -1.0, 1.0)
        ]
        return normalized
    
    def _compute_relative_target_planar(self, position: np.ndarray, target_position: np.ndarray) -> List[float]:
        """è®¡ç®—ç›¸å¯¹ç›®æ ‡ä½ç½® - å¹³é¢æ¨¡å¼ï¼ˆåªä½¿ç”¨x, yï¼‰
        
        ğŸ”§ å…³é”®ä¿®å¤ï¼šç›´æ¥è¿”å›ç›¸å¯¹ä½ç½®ï¼Œä¸å½’ä¸€åŒ–ï¼
        - è®©PPOèƒ½æ„ŸçŸ¥è·ç¦»ä¿¡æ¯
        - å½’ä¸€åŒ–ä¼šåœ¨observation_managerä¸­ç»Ÿä¸€å¤„ç†
        """
        relative = target_position[:2] - position[:2]  # åªä½¿ç”¨x, yåˆ†é‡
        
        # ç›´æ¥è¿”å›ç›¸å¯¹ä½ç½®ï¼ˆç±³ï¼‰ï¼Œä¸åšå½’ä¸€åŒ–
        # ObservationManagerä¼šç»Ÿä¸€å½’ä¸€åŒ–åˆ°[-15, 15]èŒƒå›´
        return [relative[0], relative[1]]
    
    def _normalize_velocity(self, velocity: np.ndarray) -> List[float]:
        """å½’ä¸€åŒ–é€Ÿåº¦ä¿¡æ¯"""
        # å‡è®¾æœ€å¤§é€Ÿåº¦ä¸º 5 m/s
        max_velocity = 5.0
        normalized = [
            np.clip(velocity[0] / max_velocity, -1.0, 1.0),
            np.clip(velocity[1] / max_velocity, -1.0, 1.0),
            np.clip(velocity[2] / max_velocity, -1.0, 1.0)
        ]
        return normalized
    
    def _compute_relative_target(self, position: np.ndarray, target_position: np.ndarray) -> List[float]:
        """è®¡ç®—ç›¸å¯¹ç›®æ ‡ä½ç½® - 3Dæ¨¡å¼
        
        ğŸ”§ å…³é”®ä¿®å¤ï¼šç›´æ¥è¿”å›ç›¸å¯¹ä½ç½®ï¼Œä¸å½’ä¸€åŒ–ï¼
        - è®©PPOèƒ½æ„ŸçŸ¥è·ç¦»ä¿¡æ¯
        - å½’ä¸€åŒ–ä¼šåœ¨observation_managerä¸­ç»Ÿä¸€å¤„ç†
        """
        relative = target_position - position
        
        # ç›´æ¥è¿”å›ç›¸å¯¹ä½ç½®ï¼ˆç±³ï¼‰ï¼Œä¸åšå½’ä¸€åŒ–
        # ObservationManagerä¼šç»Ÿä¸€å½’ä¸€åŒ–åˆ°[-15, 15]èŒƒå›´
        return [relative[0], relative[1], relative[2]]
    
    def _extract_depth_features(self, depth_image: np.ndarray) -> List[float]:
        """æå–æ·±åº¦ç‰¹å¾"""
        if depth_image is None or depth_image.size == 0:
            return [1.0] * self.depth_features_dim
            
        # ç¡®ä¿æ·±åº¦å›¾åƒæ˜¯2Dçš„
        if len(depth_image.shape) == 3:
            depth_image = depth_image[:, :, 0]
        elif len(depth_image.shape) == 1:
            # å¦‚æœæ˜¯1Dæ•°ç»„ï¼Œè¯´æ˜å½¢çŠ¶æœ‰é—®é¢˜ï¼Œè¿”å›é»˜è®¤å€¼
            return [1.0] * self.depth_features_dim
        
        # é‡è¦ï¼šå…ˆé¢„å¤„ç†æ·±åº¦å›¾åƒå†æå–ç‰¹å¾
        preprocessed_depth = self.depth_processor.preprocess_depth_image(depth_image)
        return self.depth_processor.get_navigation_features(preprocessed_depth).tolist()
    
    def _convert_depth_buffer(self, depth_buffer: np.ndarray) -> np.ndarray:
        """è½¬æ¢æ·±åº¦ç¼“å†²åŒºä¸ºå®é™…æ·±åº¦å€¼"""
        near = self.camera_config['near_plane']
        far = self.camera_config['far_plane']
        
        # è½¬æ¢æ·±åº¦ç¼“å†²åŒºå€¼åˆ°å®é™…æ·±åº¦
        depth_image = far * near / (far - (far - near) * depth_buffer)
        
        return depth_image.astype(np.float32)
    
    def _extract_depth_info(self, depth_image: np.ndarray) -> Dict[str, float]:
        """æå–æ·±åº¦ä¿¡æ¯"""
        # è®¡ç®—åŸºç¡€æ·±åº¦ç»Ÿè®¡
        h, w = depth_image.shape
        center_region = depth_image[h//4:3*h//4, w//4:3*w//4]
        
        depth_info = {
            'min_depth': float(np.min(center_region)),
            'mean_depth': float(np.mean(center_region)),
            'max_depth': float(np.max(center_region)),
            'std_depth': float(np.std(center_region))
        }
        
        # åŒºåŸŸåˆ†æ
        forward_region = depth_image[h//3:2*h//3, w//3:2*w//3]
        left_region = depth_image[h//4:3*h//4, :w//3]
        right_region = depth_image[h//4:3*h//4, 2*w//3:]
        
        depth_info.update({
            'forward_min': float(np.min(forward_region)),
            'left_min': float(np.min(left_region)),
            'right_min': float(np.min(right_region))
        })
        
        return depth_info


def create_default_state_config() -> Dict[str, Any]:
    """åˆ›å»ºé»˜è®¤çŠ¶æ€é…ç½®"""
    return {
        'depth_height': env_config.get('depth_height', 64),
        'depth_width': env_config.get('depth_width', 64),
        'collision_threshold': env_config.get('collision_distance', 0.8) / env_config.get('depth_scale', 7.5),
        'depth_scale': env_config.get('depth_scale', 7.5),
        'max_depth': env_config.get('max_depth', 2.0),
        'camera_fov': env_config.get('depth_fov', 70.0),
        'depth_near': env_config.get('depth_near', 0.3),
        'depth_far': env_config.get('depth_far', 15.0),
        'cnn_feature_dim': env_config.get('cnn_feature_dim', 256),
        'depth_feature_dim': env_config.get('depth_feature_dim', 130)
    }